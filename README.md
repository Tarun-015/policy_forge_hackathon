# üõ°Ô∏è DRISHTI‚ÄìNAYAN: Regulating Facial Recognition Technology (FRT) in Indian Policing

![ChatGPT Image Jun 10, 2025, 08_15_26 AM](https://github.com/user-attachments/assets/48e695bc-cd15-4af8-bfd8-aa6616a14eba)






**Hackathon Submission | PolicyForge 2025**  
**Team Member**: Tarun Chaudhary , Krish Gupta , Sayan Das, Rahul Prajapat


**Institution**: IIT Madras  
**Track**: AI Governance & Public Policy  
**Project Type**: Policy Draft + Implementation Framework  

---

## üìå Overview

Facial Recognition Technology (FRT) is transforming policing in India. While it aids in surveillance and crime prevention, the absence of legal checks raises concerns about privacy, bias, and misuse.

**DRISHTI‚ÄìNAYAN** is a comprehensive policy proposal that addresses these concerns by introducing a **dual-framework**:

- **DRISHTI**: *Draft Regulation for the Identification and Surveillance through Human-Targeted Imaging*  
- **NAYAN**: *National Accountability for Your Automated Nagrik-Identification Network*

Together, they form a citizen-centric, constitutionally grounded, and future-ready approach to regulating FRT in Indian law enforcement.

---

## üéØ Objectives

- Create a legal boundary for FRT usage in public spaces  
- Protect fundamental rights (privacy, expression, protest)  
- Establish technical and ethical oversight mechanisms  
- Ensure accountability through audits, impact assessments, and redressal pathways  

---

## üß† Key Challenges Addressed

- **Privacy Invasion** through mass and covert surveillance  
- **Algorithmic Bias**, especially against minorities and women  
- **Lack of Accountability** in wrongful arrests and misuse  
- **Suppression of Civil Liberties** like protest and free speech  

---

## üîç Scope of the Policy

Applies to:
- State Police & CAPFs
- Intelligence units under MHA

Use-Cases Covered:
- Surveillance in public places
- Monitoring protests and mass events
- Real-time face-matching via CCTV/drones
- Integration with crime databases like CCTNS/NCRB

Excludes:
- Commercial/private FRT (covered under Digital Personal Data Protection Act)

---

## üìà Policy Pillars

| Domain            | Framework/Action Items                                                                 |
|-------------------|----------------------------------------------------------------------------------------|
| **Legal Oversight**     | Privacy Impact Assessment (PIA), legal vetting, citizen consent mandate               |
| **Technical Vetting**   | Bias & discrimination testing, India-trained AI model validation                    |
| **Institutional Setup** | FRT Ethics Board of India (FEBI), NHRC oversight, MHA + MeitY coordination          |
| **Public Trust**        | Grievance redressal portals, transparency dashboards, public awareness campaigns    |


## üõ†Ô∏è Tools Used

- **Research Sources**: Al Jazeera, Wired, Times of India, Government policy papers  
- **Document Creation**: Microsoft Word, PDF Editor  
- **Visualization**: Canva, Excel (for budget models)  

---

## üß© Key Benefits

- Helps identify missing children and human trafficking suspects  
- Increases public safety in transit hubs and smart cities  
- Lays groundwork for ethical AI deployment in governance  
- Balances national security with citizen dignity

---

## üìö References

- [Al Jazeera Report on Hyderabad FRT Use](https://www.aljazeera.com/news/2021/12/20/in-hyderabad-indias-facial-recognition-rollout-raises-concerns)  
- [Wired Report on Delhi Police AFRS](https://www.wired.com/story/india-facial-recognition-anti-caa-protests/)  
- [Digital India Initiatives](https://digitalindia.gov.in)  
- Government of India FRT Initiatives (AFRS, Digi Yatra, Smart Cities)

---

## ‚úÖ Final Message

India stands at a critical point in choosing how it embraces technology in governance. **DRISHTI‚ÄìNAYAN** is not anti-surveillance ‚Äî it is pro-democracy. By anchoring technological advancements in transparency and ethics, this framework allows India to lead the Global South in **human-centric AI policy design**.

---

